{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAuq2aeRX0Wo",
        "outputId": "30e3b089-ff6a-4e62-dc7f-dccbef1022f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting plot_keras_history\n",
            "  Downloading plot_keras_history-1.1.38.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from plot_keras_history) (3.7.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from plot_keras_history) (2.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from plot_keras_history) (1.11.4)\n",
            "Collecting support_developer>=1.0.2 (from plot_keras_history)\n",
            "  Downloading support_developer-1.0.5.tar.gz (4.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sanitize_ml_labels>=1.0.48 (from plot_keras_history)\n",
            "  Downloading sanitize_ml_labels-1.0.51.tar.gz (322 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.5/322.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting compress_json (from sanitize_ml_labels>=1.0.48->plot_keras_history)\n",
            "  Downloading compress_json-1.0.10.tar.gz (6.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->plot_keras_history) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->plot_keras_history) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->plot_keras_history) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->plot_keras_history) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib->plot_keras_history) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->plot_keras_history) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->plot_keras_history) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->plot_keras_history) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->plot_keras_history) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->plot_keras_history) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->plot_keras_history) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->plot_keras_history) (1.16.0)\n",
            "Building wheels for collected packages: plot_keras_history, sanitize_ml_labels, support_developer, compress_json\n",
            "  Building wheel for plot_keras_history (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for plot_keras_history: filename=plot_keras_history-1.1.38-py3-none-any.whl size=9456 sha256=7f201e2608b79526df1f0e8930cb6ae7fb6c84bfbac8f74b44dabe44ec4c64e3\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/31/6c/bbc9703b7baa8bd3802a8aedd9e2f9e66941b0cf0d456ab4cc\n",
            "  Building wheel for sanitize_ml_labels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sanitize_ml_labels: filename=sanitize_ml_labels-1.0.51-py3-none-any.whl size=321866 sha256=b485667699c211519af5863e9c788f5ec98601609c3ba6f1c3618aa3f2d2cd07\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/9f/f5/37d037c39ac8b305590d5956f7021c6ca94b63c68be24f6841\n",
            "  Building wheel for support_developer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for support_developer: filename=support_developer-1.0.5-py3-none-any.whl size=5630 sha256=d451f45b4da75aa37f891c7c48bf9f2ad600cbae02b939f687d720a84b4136b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/72/c8/3054a5897ba0713dfa7a941364d68cbd42b0755c8e2ec1c18c\n",
            "  Building wheel for compress_json (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for compress_json: filename=compress_json-1.0.10-py3-none-any.whl size=5817 sha256=7ad14d430d8d49098cf4717ede0b4244933153c9c7c299bb6fc4148218c1df79\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/55/94/bc79987b855aac5990e0d015c2e604aa50bc5147673e98530c\n",
            "Successfully built plot_keras_history sanitize_ml_labels support_developer compress_json\n",
            "Installing collected packages: support_developer, compress_json, sanitize_ml_labels, plot_keras_history\n",
            "Successfully installed compress_json-1.0.10 plot_keras_history-1.1.38 sanitize_ml_labels-1.0.51 support_developer-1.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install mlflow\n",
        "!pip install plot_keras_history\n",
        "\n",
        "\n",
        "\n",
        "import mlflow\n",
        "import mlflow.keras\n",
        "from mlflow.tracking import MlflowClient\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "from plot_keras_history import show_history\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import h5py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up MLflow\n",
        "mlflow.set_tracking_uri(\"http://localhost:5000\")  # Replace with your MLflow tracking URI\n",
        "mlflow.set_experiment(\"MNIST Digit Classification\")  # Set the experiment name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vI51xvP-X0Wp",
        "outputId": "8a5ed8ce-918f-4c41-e1f2-f31dd9c96525"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 784) train input samples\n",
            "(10000, 784) test input samples\n"
          ]
        }
      ],
      "source": [
        "(X_train, Y_train), (X_test, Y_test) = keras.datasets.mnist.load_data()\n",
        "num_classes = 10\n",
        "x_train = X_train.reshape(60000, 784)\n",
        "x_test = X_test.reshape(10000, 784)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x_train.shape, 'train input samples')\n",
        "print(x_test.shape, 'test input samples')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3bElstJX0Wq",
        "outputId": "cf8ab654-6ed1-4599-9586-8d08a8334b7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 10) train output samples\n",
            "(10000, 10) test output samples\n"
          ]
        }
      ],
      "source": [
        "y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(Y_test, num_classes)\n",
        "print(y_train.shape, 'train output samples')\n",
        "print(y_test.shape, 'test output samples')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "7kM7diRYX0Wq",
        "outputId": "757af904-b008-468e-92bd-02cc470aeb3b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeUAAAGfCAYAAABhicrFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAwi0lEQVR4nO3df3SU5Zn/8U+CMKAmkwYkQ9YE44+CRwR7KIkRZFGyhLS18qO1enoq/qg/MLAFVNy0FZTajuKutSjFbrVBdkUsVkDZnnQxSFhbwEOEcliBAosSJQmCm0kIkmByf//g66yRe0gmzGTumXm/zrnPYa558jzXEybXNc/MPfekGGOMAABAzKXGOgEAAHAKTRkAAEfQlAEAcARNGQAAR9CUAQBwBE0ZAABH0JQBAHAETRkAAEfQlAEAcARNGQAAR5wTrR0vXrxYTz75pOrq6jRixAg988wzys/P7/Tn2tvbdejQIaWlpSklJSVa6QHdYoxRU1OTsrOzlZrKc9pI627dkKgdcFuXa4eJghUrVpg+ffqY3/3ud+a///u/zV133WUyMjJMfX19pz9bU1NjJDEYTo+amppo/OkktbOpG8ZQOxjxMTqrHVFpyvn5+aa0tDR4u62tzWRnZxu/39/pzzY0NMT8l8ZgdDYaGhqi8aeT1M6mbhhD7WDEx+isdkT89bfW1lZVV1erqKgoGEtNTVVRUZE2bdp02vYtLS1qbGwMjqampkinBEQcL49GVrh1Q6J2ID51Vjsi3pSPHDmitrY2ZWVldYhnZWWprq7utO39fr+8Xm9w5OTkRDolAI4Lt25I1A4kppjPVCkrK1MgEAiOmpqaWKcEIA5QO5CIIj77esCAAerVq5fq6+s7xOvr6+Xz+U7b3uPxyOPxRDoNAHEk3LohUTuQmCJ+pdynTx+NHDlSlZWVwVh7e7sqKytVWFgY6cMBSADUDeCUqHxOec6cOZo2bZq+/vWvKz8/X08//bSam5t1++23R+NwABIAdQOIUlP+3ve+p48//ljz5s1TXV2drrrqKlVUVJw2iQMAPkfdAKQUY4yJdRJf1NjYKK/XG+s0gDMKBAJKT0+PdRr4AmoH4kFntSPms68BAMApNGUAABxBUwYAwBE0ZQAAHEFTBgDAETRlAAAcQVMGAMARNGUAABxBUwYAwBE0ZQAAHEFTBgDAETRlAAAcQVMGAMARNGUAABwRle9Thlv+/u//3hq/7rrrrPEFCxZY4+3t7RHLCQBwOq6UAQBwBE0ZAABH0JQBAHAETRkAAEdEvCk/8sgjSklJ6TCGDh0a6cMASCDUDeCUqMy+vuKKK/Tmm2/+30HOYZK3i+bNm2eNnzx50hr/+c9/Hs10kOSoG6Glptqvny666CJr/J577oliNtG3fft2a3zt2rXWeGtrqzXe0tISqZR6TFQe9eecc458Pl80dg0gQVE3gCi9p7x3715lZ2fr4osv1ve//30dPHgw5LYtLS1qbGzsMAAkn3DqhkTtQGKKeFMuKCjQ0qVLVVFRoSVLlujAgQO69tpr1dTUZN3e7/fL6/UGR05OTqRTAuC4cOuGRO1AYop4Uy4pKdF3v/tdDR8+XMXFxfrjH/+ohoYG/f73v7duX1ZWpkAgEBw1NTWRTgmA48KtGxK1A4kp6jMpMjIy9NWvflX79u2z3u/xeOTxeKKdBoA40lndkKgdSExRb8rHjh3T/v379YMf/CDah0KEXH311bFOAUmOutHRpZdeao3v3r27hzNx07Zt26zxb33rW9Z4XV2dNW6MiVhO3RXxl68feOABVVVV6f3339df/vIXTZ48Wb169dItt9wS6UMBSBDUDeCUiF8pf/jhh7rlllt09OhRXXDBBRozZow2b96sCy64INKHApAgqBvAKRFvyitWrIj0LgEkOOoGcAprXwMA4AiaMgAAjmBxWQBw3OHDh63xjRs3WuNjx46NZjrO+drXvmaNf/TRR9b4gAEDrPFPPvkkYjl1F1fKAAA4gqYMAIAjaMoAADiCpgwAgCNoygAAOILZ1wDguIaGBmt88uTJ1vjLL79sjQ8ZMsQaD/Xd1cuWLes8uSi46qqrrPF7773XGu/Vq1dY+58/f741/qMf/Sis/UQDV8oAADiCpgwAgCNoygAAOIKmDACAI2jKAAA4gtnXSeDGG2+MdQoAouB///d/rfGJEyf2cCY9o6qqyhovLy+3xs877zxrfObMmdY4s68BAEAQTRkAAEfQlAEAcARNGQAAR4TdlDdu3KgbbrhB2dnZSklJ0erVqzvcb4zRvHnzNGjQIPXr109FRUXau3dvpPIFEIeoG0DXhD37urm5WSNGjNAdd9yhKVOmnHb/woULtWjRIr344ovKy8vTww8/rOLiYr333nvq27dvRJJGeK688sqwtv/444+jlAmSFXUDkfDWW29Z421tbT2cSfSE3ZRLSkpUUlJivc8Yo6efflo//elPgx/DWbZsmbKysrR69WrdfPPNZ5ctgLhE3QC6JqLvKR84cEB1dXUqKioKxrxerwoKCrRp0ybrz7S0tKixsbHDAJA8ulM3JGoHElNEm3JdXZ0kKSsrq0M8KysreN+X+f1+eb3e4MjJyYlkSgAc1526IVE7kJhiPvu6rKxMgUAgOGpqamKdEoA4QO1AIopoU/b5fJKk+vr6DvH6+vrgfV/m8XiUnp7eYQBIHt2pGxK1A4kpomtf5+XlyefzqbKyUldddZUkqbGxUVu2bNH06dMjeShE0W9+85tYp4AkQt1AV82aNcsaD/cJ2cqVKyOQTXSE3ZSPHTumffv2BW8fOHBA27dvV2ZmpnJzczVr1iw99thjuuyyy4IfbcjOztakSZMimTeAOELdALom7Ka8detWXXfddcHbc+bMkSRNmzZNS5cu1dy5c9Xc3Ky7775bDQ0NGjNmjCoqKvisIZDEqBtA14TdlMeNGydjTMj7U1JStGDBAi1YsOCsEgOQOKgbQNfEfPY1AAA4haYMAIAjIjr7GrH1xRWRvujzGa0AEA8GDhxojUdqNv78+fMjsp9o4EoZAABH0JQBAHAETRkAAEfQlAEAcARNGQAARzD7OoHMnj3bGu/fv38PZwIAnfvy13V+bvXq1dZ4ZmZmWPsP9c1hX1zy1TVcKQMA4AiaMgAAjqApAwDgCJoyAACOoCkDAOAIZl8nsa1bt1rju3bt6uFMAHTH8OHDrfERI0ZY4z/84Q/D2v+BAwes8Zdeeims/YTy6KOPWuMFBQVh7efgwYPW+GOPPWaNf/bZZ2HtvydxpQwAgCNoygAAOIKmDACAI2jKAAA4IuymvHHjRt1www3Kzs5WSkrKacuh3XbbbUpJSekwJk6cGKl8AcQh6gbQNWHPvm5ubtaIESN0xx13aMqUKdZtJk6cqPLy8uBtj8fT/QwRNQ0NDdZ4Y2NjzyaChEfd6GjYsGHW+ODBg63xG2+80RoP9bsMd43oUK699lpr/NZbb43I/iPliSeesMaff/75Hs7k7IXdlEtKSlRSUnLGbTwej3w+X7eTApBYqBtA10TlPeUNGzZo4MCBGjJkiKZPn66jR4+G3LalpUWNjY0dBoDkE07dkKgdSEwRb8oTJ07UsmXLVFlZqSeeeEJVVVUqKSlRW1ubdXu/3y+v1xscOTk5kU4JgOPCrRsStQOJKeIret18883Bf1955ZUaPny4LrnkEm3YsEHjx48/bfuysjLNmTMneLuxsZE/LiDJhFs3JGoHElPUPxJ18cUXa8CAASG/VNrj8Sg9Pb3DAJDcOqsbErUDiSnqa19/+OGHOnr0qAYNGhTtQyFMu3fvjnUKgFWi1I1Qazi/8cYb1viAAQOimU7cmzBhgjW+YcOGnk0kisJuyseOHevw7PXAgQPavn27MjMzlZmZqUcffVRTp06Vz+fT/v37NXfuXF166aUqLi6OaOIA4gd1A+iasJvy1q1bdd111wVvf/6ezrRp07RkyRLt2LFDL774ohoaGpSdna0JEyboZz/7WUJ/5hDAmVE3gK4JuymPGzdOxpiQ9//pT386q4QAJB7qBtA1rH0NAIAjaMoAADgi6rOv4a5XX3011ikACeH++++3xsvKyqzxUGtTNzc3W+PLli2zxl966SVr/IUXXrDGhwwZYo3Hi507d1rjn332WQ9nEj1cKQMA4AiaMgAAjqApAwDgCJoyAACOoCkDAOAIZl8DQBfNnj3bGv/JT35ijWdkZIS1/3Xr1lnje/futcaXL19ujefm5oZ13HB99NFH1vj69eut8W9/+9vWuNfrDeu4ixYtssZ/8IMfWOMtLS1h7d8FXCkDAOAImjIAAI6gKQMA4AiaMgAAjqApAwDgCGZfA0AXPfLII9Z4WlpaRPY/adKksOKRUldXZ43fdNNN1vjf/vY3a/zw4cPW+KBBg6zxWbNmWeP33XefNf6d73zHGt+1a5c1Pn/+fGvcZVwpAwDgCJoyAACOoCkDAOAImjIAAI4Iqyn7/X6NGjVKaWlpGjhwoCZNmqQ9e/Z02ObEiRMqLS1V//79df7552vq1Kmqr6+PaNIA4gu1A+iasGZfV1VVqbS0VKNGjdJnn32mH//4x5owYYLee+89nXfeeZJOrQ37H//xH1q5cqW8Xq9mzJihKVOm6M9//nNUTgCdS0lJiXUKSHKJUjvS09OtcWNMD2dyZhUVFdb4L37xC2v8vffes8Y/+eSTiORTW1trjT/00EPW+D//8z9b4w888IA1vmPHju4l5qCwmvKX/6OXLl2qgQMHqrq6WmPHjlUgENALL7yg5cuX6/rrr5cklZeX6/LLL9fmzZt19dVXRy5zAHGD2gF0zVm9pxwIBCRJmZmZkqTq6mqdPHlSRUVFwW2GDh2q3Nxcbdq0ybqPlpYWNTY2dhgAEhu1A7DrdlNub2/XrFmzNHr0aA0bNkzSqQ+g9+nT57SvK8vKygr54XS/3y+v1xscOTk53U0JQBygdgChdbspl5aWaufOnVqxYsVZJVBWVqZAIBAcNTU1Z7U/AG6jdgChdWuZzRkzZmjt2rXauHGjLrzwwmDc5/OptbVVDQ0NHZ7x1tfXy+fzWffl8Xjk8Xi6kwaAOEPtAM4srKZsjNHMmTO1atUqbdiwQXl5eR3uHzlypHr37q3KykpNnTpVkrRnzx4dPHhQhYWFkcsaYQk1M/SNN96wxsePH2+Nb926NWI5IbkkSu0ItRb0K6+8EpH9v/nmm9b4xo0brfFf//rX1vixY8es8dbW1u4l1sM+/vhjazzUbO1EElZTLi0t1fLly7VmzRqlpaUF3+vxer3q16+fvF6v7rzzTs2ZM0eZmZlKT0/XzJkzVVhYyOxJIIlRO4CuCaspL1myRJI0bty4DvHy8nLddtttkqRf/vKXSk1N1dSpU9XS0qLi4uKQz+YAJAdqB9A1Yb983Zm+fftq8eLFWrx4cbeTApBYqB1A17D2NQAAjqApAwDgiG59JAqJ4ejRo9b44cOHezgTID68+uqr1nioNbHD1dLSYo2fPHkyIvuH+7hSBgDAETRlAAAcQVMGAMARNGUAABxBUwYAwBHMvk4CBw8etMa/+N21XdkeSHahFkEJtdY0EC6ulAEAcARNGQAAR9CUAQBwBE0ZAABH0JQBAHAEs68TyDe/+c1YpwAAOAtcKQMA4AiaMgAAjqApAwDgCJoyAACOCKsp+/1+jRo1SmlpaRo4cKAmTZqkPXv2dNhm3LhxSklJ6TDuvffeiCYNIL5QO4CuCaspV1VVqbS0VJs3b9a6det08uRJTZgwQc3NzR22u+uuu1RbWxscCxcujGjSAOILtQPomrA+ElVRUdHh9tKlSzVw4EBVV1dr7Nixwfi5554rn88XmQwBxD1qB9A1Z/WeciAQkCRlZmZ2iL/00ksaMGCAhg0bprKyMh0/fjzkPlpaWtTY2NhhAEhs1A4gBNNNbW1t5pvf/KYZPXp0h/hvfvMbU1FRYXbs2GH+/d//3fzd3/2dmTx5csj9zJ8/30hiMOJqBAKB7v7pJD1qByOZR2e1o9tN+d577zWDBw82NTU1Z9yusrLSSDL79u2z3n/ixAkTCASCo6amJua/NAajs0FT7j5qByOZR2e1o1vLbM6YMUNr167Vxo0bdeGFF55x24KCAknSvn37dMkll5x2v8fjkcfj6U4aAOIMtQM4s7CasjFGM2fO1KpVq7Rhwwbl5eV1+jPbt2+XJA0aNKhbCQKIf9QOoGvCasqlpaVavny51qxZo7S0NNXV1UmSvF6v+vXrp/3792v58uX6xje+of79+2vHjh2aPXu2xo4dq+HDh0flBAC4j9oBdFE47wUpxGvk5eXlxhhjDh48aMaOHWsyMzONx+Mxl156qXnwwQfDev8tEAjE/DV/BqOzwXvK4Qn1e6R2MJJtdPaYTvn/fzDOaGxslNfrjXUawBkFAgGlp6fHOg18AbUD8aCz2sHa1wAAOIKmDACAI2jKAAA4gqYMAIAjaMoAADiCpgwAgCNoygAAOMK5puzYx6YBKx6n7uH/BPGgs8epc025qakp1ikAneJx6h7+TxAPOnucOreiV3t7uw4dOqS0tDQ1NTUpJydHNTU1SbF6UmNjI+frOGOMmpqalJ2drdRU557TJjVqB+frsq7Wjm59dWM0paamBr/SLSUlRZKUnp4eN7/4SOB83cZSjm6idnC+rutK7eCpPgAAjqApAwDgCKebssfj0fz58+XxeGKdSo/gfIHISLbHFuebOJyb6AUAQLJy+koZAIBkQlMGAMARNGUAABxBUwYAwBFON+XFixfroosuUt++fVVQUKB33nkn1ilFxMaNG3XDDTcoOztbKSkpWr16dYf7jTGaN2+eBg0apH79+qmoqEh79+6NTbIR4Pf7NWrUKKWlpWngwIGaNGmS9uzZ02GbEydOqLS0VP3799f555+vqVOnqr6+PkYZI54lat2Qkqt2JGvdcLYpv/LKK5ozZ47mz5+vd999VyNGjFBxcbEOHz4c69TOWnNzs0aMGKHFixdb71+4cKEWLVqk5557Tlu2bNF5552n4uJinThxooczjYyqqiqVlpZq8+bNWrdunU6ePKkJEyaoubk5uM3s2bP1xhtvaOXKlaqqqtKhQ4c0ZcqUGGaNeJTIdUNKrtqRtHXDOCo/P9+UlpYGb7e1tZns7Gzj9/tjmFXkSTKrVq0K3m5vbzc+n888+eSTwVhDQ4PxeDzm5ZdfjkGGkXf48GEjyVRVVRljTp1f7969zcqVK4Pb7Nq1y0gymzZtilWaiEPJUjeMSb7akSx1w8kr5dbWVlVXV6uoqCgYS01NVVFRkTZt2hTDzKLvwIEDqqur63DuXq9XBQUFCXPugUBAkpSZmSlJqq6u1smTJzuc89ChQ5Wbm5sw54zoS+a6ISV+7UiWuuFkUz5y5Ija2tqUlZXVIZ6VlaW6uroYZdUzPj+/RD339vZ2zZo1S6NHj9awYcMknTrnPn36KCMjo8O2iXLO6BnJXDekxK4dyVQ3nPuWKCS20tJS7dy5U2+//XasUwEQJ5Kpbjh5pTxgwAD16tXrtFl09fX18vl8McqqZ3x+fol47jNmzNDatWv11ltvBb9iTzp1zq2trWpoaOiwfSKcM3pOMtcNKXFrR7LVDSebcp8+fTRy5EhVVlYGY+3t7aqsrFRhYWEMM4u+vLw8+Xy+Dufe2NioLVu2xO25G2M0Y8YMrVq1SuvXr1deXl6H+0eOHKnevXt3OOc9e/bo4MGDcXvO6HnJXDekxKsdSVs3Yj3TLJQVK1YYj8djli5dat577z1z9913m4yMDFNXVxfr1M5aU1OT2bZtm9m2bZuRZJ566imzbds288EHHxhjjHn88cdNRkaGWbNmjdmxY4e58cYbTV5envn0009jnHn3TJ8+3Xi9XrNhwwZTW1sbHMePHw9uc++995rc3Fyzfv16s3XrVlNYWGgKCwtjmDXiUSLXDWOSq3Yka91wtikbY8wzzzxjcnNzTZ8+fUx+fr7ZvHlzrFOKiLfeestIOm1MmzbNGHPqow0PP/ywycrKMh6Px4wfP97s2bMntkmfBdu5SjLl5eXBbT799FNz3333ma985Svm3HPPNZMnTza1tbWxSxpxK1HrhjHJVTuStW7w1Y0AADjCyfeUAQBIRjRlAAAcQVMGAMARNGUAABxBUwYAwBE0ZQAAHEFTBgDAETRlAAAcQVMGAMARNGUAABzh3Pcpt7e369ChQ0pLS1NKSkqs0wE6MMaoqalJ2dnZSk3lOa1LqB1wWZdrR7QW1X722WfN4MGDjcfjMfn5+WbLli1d+rmampqQC5EzGK6MmpqaaP3pJLXu1g1jqB2M+Bid1Y6oPNV/5ZVXNGfOHM2fP1/vvvuuRowYoeLiYh0+fLjTn01LS4tGSkBE8TiNvLOpGxL/J4gPnT5Oz/aZrU1+fr4pLS0N3m5razPZ2dnG7/eftu2JEydMIBAIDp7tMuJhBAKBaPzpJLVw6oYx1A5GfI7OakfEr5RbW1tVXV2toqKiYCw1NVVFRUXatGnTadv7/X55vd7gyMnJiXRKABwXbt2QqB1ITBFvykeOHFFbW5uysrI6xLOyslRXV3fa9mVlZQoEAsFRU1MT6ZQAOC7cuiFRO5CYYj772uPxyOPxxDoNAHGG2oFEFPEr5QEDBqhXr16qr6/vEK+vr5fP54v04QAkAOoGcErEm3KfPn00cuRIVVZWBmPt7e2qrKxUYWFhpA8HIAFQN4BTovLy9Zw5czRt2jR9/etfV35+vp5++mk1Nzfr9ttvj8bhACQA6gYQpab8ve99Tx9//LHmzZunuro6XXXVVaqoqDhtEgcAfI66AUgpxhgT6yS+qLGxUV6vN9ZpAGcUCASUnp4e6zTwBdQOxIPOageL9wIA4AiaMgAAjqApAwDgCJoyAACOoCkDAOAImjIAAI6gKQMA4AiaMgAAjqApAwDgCJoyAACOoCkDAOAImjIAAI6gKQMA4AiaMgAAjqApAwDgCJoyAACOoCkDAOAImjIAAI6gKQMA4IhzIr3DRx55RI8++miH2JAhQ7R79+5IHwpfkpWVZY1fdtllIX9mypQp1nh6ero1npGREdZ+brrpJmv81VdfDZkTkg91Azgl4k1Zkq644gq9+eab/3eQc6JyGAAJhLoBRKkpn3POOfL5fF3atqWlRS0tLcHbjY2N0UgJgOPCqRsStQOJKSrvKe/du1fZ2dm6+OKL9f3vf18HDx4Mua3f75fX6w2OnJycaKQEwHHh1A2J2oHEFPGmXFBQoKVLl6qiokJLlizRgQMHdO2116qpqcm6fVlZmQKBQHDU1NREOiUAjgu3bkjUDiSmiL98XVJSEvz38OHDVVBQoMGDB+v3v/+97rzzztO293g88ng8kU4DQBwJt25I1A4kpqjPpMjIyNBXv/pV7du3L9qHcl5aWpo17vV6rfGHHnrIGi8qKgprP4MGDQqZkzEm5H2R8KMf/cgaZ/Y1zoS60TW33XabNT537lxrfMiQIWHt//nnn7fG77nnnrD2E0qoOQQTJ060xsvLy63xX/ziF9b4ypUrrfHt27d3nlyMRP1zyseOHdP+/fvP2BgA4IuoG0hWEW/KDzzwgKqqqvT+++/rL3/5iyZPnqxevXrplltuifShACQI6gZwSsRfvv7www91yy236OjRo7rgggs0ZswYbd68WRdccEGkDwUgQVA3gFMi3pRXrFgR6V0CSHDUDeAU1r4GAMARrGN3Fq644gprPNSM4+LiYms82osedGeGdW1trTX+zjvvhLWff/mXfwn72AA6+qd/+idr/Oc//7k13t7eHlY8lDvuuMMa/8lPfmKNHzlyJKz9Dx061Br/7W9/a42Hyj/UbPMvrvj2RUk9+xoAAHQNTRkAAEfQlAEAcARNGQAAR9CUAQBwBLOvz8Ktt95qjf/whz+M6nH37t1rjb/++uvW+OOPPx72MVpbW63xM31rD4Czc9FFF1nj3/3ud3s2kU4sXLjQGg81WzuUG2+8MRLpJBSulAEAcARNGQAAR9CUAQBwBE0ZAABH0JQBAHAEs6/PwtatW63x//qv/7LG3377bWt81KhR1nhRUZE1fs0111jjR48etcYBuCXULOtQn6C4/PLLI3Lc999/3xqfN2+eNR5qlvWDDz5ojfft29ca9/v91vj06dOt8XBVVlZa47/61a8isv+exJUyAACOoCkDAOAImjIAAI6gKQMA4AiaMgAAjgh79vXGjRv15JNPqrq6WrW1tVq1apUmTZoUvN8Yo/nz5+u3v/2tGhoaNHr0aC1ZskSXXXZZJPN2wsqVK8OKh7J79+5IpAM4i7rR0bRp06zxSM2yPnLkiDX+ne98xxr/61//ao0fPHjQGp88ebI1/uabb1rjM2bMsMbDFeoTLKF+n4FAICLH7UlhXyk3NzdrxIgRWrx4sfX+hQsXatGiRXruuee0ZcsWnXfeeSouLtaJEyfOOlkA8Ym6AXRN2FfKJSUlKikpsd5njNHTTz+tn/70p8Fv/1i2bJmysrK0evVq3Xzzzaf9TEtLi1paWoK3Gxsbw00JgOMiXTckagcSU0TfUz5w4IDq6uo6LHrh9XpVUFCgTZs2WX/G7/fL6/UGR05OTiRTAuC47tQNidqBxBTRplxXVydJysrK6hDPysoK3vdlZWVlCgQCwVFTUxPJlAA4rjt1Q6J2IDHFfJlNj8cjj8cT6zQAxBlqBxJRRJuyz+eTJNXX12vQoEHBeH19va666qpIHiouDR8+3BoP92W3Xr16WeOhZn1feeWVIfdljLHGy8vLrfFnn33WGj9+/HjIYwBnkox1IyUlxRpPTQ3vxctQ24d6Hz7ULOtQ/vznP1vj9fX11vgf//hHazxUnqFeCbnpppvCyieRRPTl67y8PPl8vg6Lgzc2NmrLli0qLCyM5KEAJAjqBvB/wr5SPnbsmPbt2xe8feDAAW3fvl2ZmZnKzc3VrFmz9Nhjj+myyy5TXl6eHn74YWVnZ3f4TCKA5ELdALom7Ka8detWXXfddcHbc+bMkXTqw9tLly7V3Llz1dzcrLvvvlsNDQ0aM2aMKioqQn6lF4DER90Auibspjxu3LiQ70NKp94rWbBggRYsWHBWiQFIHNQNoGtY+xoAAEfE/CNRyWTHjh3WeKj1XP/hH/7BGp8+fbo1PnXqVGv8k08+CZlTbW2tNf74449b49dff701PnHixJDHANBRqFcN2tvbo7r/cA0YMMAaf/31163xUGuVhzqvXbt2WePJMMs6FK6UAQBwBE0ZAABH0JQBAHAETRkAAEfQlAEAcASzrx3w5W/H6cxDDz1kjTc0NFjjZ5oZvX//fms81OzK8ePHW+NlZWXWuN/vD3lsANExbdo0azzUmtsffPCBNf6HP/zBGh8yZIg1Hu7s8TVr1oS1fTLgShkAAEfQlAEAcARNGQAAR9CUAQBwBE0ZAABHpJhILZIaIY2NjfJ6vbFOo0eFWv811AzHUEKtfb1q1aqwc8rMzLTGQ83WDvV/NnToUGv8b3/7W9g5uSQQCCg9PT3WaeAL4ql2ZGRkWOOvvPKKNR5qzfnUVPt1VahZ0IFAwBpfvHixNf7jH/84Isd9//33rfExY8ZY4/X19dZ4IuisdnClDACAI2jKAAA4gqYMAIAjaMoAADiCpgwAgCPCnn29ceNGPfnkk6qurlZtba1WrVqlSZMmBe+/7bbb9OKLL3b4meLiYlVUVHRp//E0gzJSnn/+eWv8jjvusMbr6uqs8a997WvWeCRnMj7wwAPW+MKFC63xLz8WPnf77bdHLKdYYPZ1eKJdN6TEqB0+n88aDzUrO9Ts5XDXoA5XqNnXhw8ftsZDrb//17/+NWI5xYuIz75ubm7WiBEjQk6hl079B9TW1gbHyy+/HO5hACQQ6gbQNWF/S1RJSYlKSkrOuI3H4wn5jO/LWlpa1NLSErzd2NgYbkoAHBfpuiFRO5CYovKe8oYNGzRw4EANGTJE06dP19GjR0Nu6/f75fV6gyMnJycaKQFwXDh1Q6J2IDFFvClPnDhRy5YtU2VlpZ544glVVVWppKREbW1t1u3LysoUCASCo6amJtIpAXBcuHVDonYgMYX98nVnbr755uC/r7zySg0fPlyXXHKJNmzYoPHjx5+2vcfjkcfjiXQaAOJIuHVDonYgMUW8KX/ZxRdfrAEDBmjfvn0h/7iS3R/+8AdrPNTs63Xr1lnjPbFe7Nq1a63xULOvx40bZ42HWlv7k08+6VZeSCzJWjdCfbLi3/7t36zxsWPHRjOdkELNvj5+/Lg1noyzrLsr6p9T/vDDD3X06FENGjQo2ocCkCCoG0hWYV8pHzt2TPv27QvePnDggLZv367MzExlZmbq0Ucf1dSpU+Xz+bR//37NnTtXl156qYqLiyOaOID4Qd0Auibsprx161Zdd911wdtz5syRJE2bNk1LlizRjh079OKLL6qhoUHZ2dmaMGGCfvazn/HeD5DEqBtA14TdlMeNG6czLQL2pz/96awSApB4qBtA17D2NQAAjoj67Gt0rrKy0hr/4trAXxTOesCxNnjwYGv8ggsusMaZfQ2cLtT6+Hv37rXGn3rqKWt8+PDhEcvJJlSe6DqulAEAcARNGQAAR9CUAQBwBE0ZAABH0JQBAHAEs68d0Nraao2//vrrPZxJ5H366afW+Be/BxdA91RVVVnjgUCghzM55c4777TG/X5/D2cSv7hSBgDAETRlAAAcQVMGAMARNGUAABxBUwYAwBHMvkZUvfvuu9b4+++/37OJAIi6UF+1edFFF1nj1IHTcaUMAIAjaMoAADiCpgwAgCNoygAAOIKmDACAI8Kafe33+/Xaa69p9+7d6tevn6655ho98cQTGjJkSHCbEydO6P7779eKFSvU0tKi4uJi/frXv1ZWVlbEk0fP4/8R3UHtiI4xY8ZY45dddlkPZ3KKz+ezxm+99VZrfMGCBdFMJy6FdaVcVVWl0tJSbd68WevWrdPJkyc1YcIENTc3B7eZPXu23njjDa1cuVJVVVU6dOiQpkyZEvHEAcQPagfQNWFdKVdUVHS4vXTpUg0cOFDV1dUaO3asAoGAXnjhBS1fvlzXX3+9JKm8vFyXX365Nm/erKuvvvq0fba0tHT4xqDGxsbunAcAh1E7gK45q/eUP/96sMzMTElSdXW1Tp48qaKiouA2Q4cOVW5urjZt2mTdh9/vl9frDY6cnJyzSQlAHKB2AHbdbsrt7e2aNWuWRo8erWHDhkmS6urq1KdPH2VkZHTYNisrS3V1ddb9lJWVKRAIBEdNTU13UwIQB6gdQGjdXmaztLRUO3fu1Ntvv31WCXg8npBLswFIPNQOILRuNeUZM2Zo7dq12rhxoy688MJg3OfzqbW1VQ0NDR2e8dbX14eclZdMdu/ebY03NDRY4xMmTLDGe+K9s8+vYL5s+fLlYe3n0UcfjUQ6SBDUjsgK9SpCU1OTNZ6dnR2R46am8mnaaAnrN2uM0YwZM7Rq1SqtX79eeXl5He4fOXKkevfurcrKymBsz549OnjwoAoLCyOTMYC4Q+0AuiasK+XS0lItX75ca9asUVpaWvBZmtfrVb9+/eT1enXnnXdqzpw5yszMVHp6umbOnKnCwkLr7EkAyYHaAXRNWE15yZIlkqRx48Z1iJeXl+u2226TJP3yl79Uamqqpk6d2mEBAADJi9oBdE1YTdkY0+k2ffv21eLFi7V48eJuJwUgsVA7gK7h3XoAABzR7Y9EIXx9+/a1xvPz863xULO1Z82aZY2/+eab1nhubm7InL71rW9Z4/fdd581Hmom7AsvvBBWTgDO3rFjx6zxTz/91Bpvb2+PZjpqbW21xkN9wgSn40oZAABH0JQBAHAETRkAAEfQlAEAcARNGQAARzD7ugeNHz/eGl+wYIE1fsstt1jjK1assMY//zq8Lws161tSyAX9Q62d++yzz1rj999/f8hjAIiOUGtfh6oF0fbRRx9Z44sWLerhTOIXV8oAADiCpgwAgCNoygAAOIKmDACAI2jKAAA4gtnXPWj//v3W+OdfXfdla9eutcYfeugha3z48OFh57Rjxw5rfO7cudb4f/7nf4Z9DAA9a+bMmdb4r371K2u8oKDAGj/TJzdsdu3aFdb2OB1XygAAOIKmDACAI2jKAAA4gqYMAIAjaMoAADgixRhjurqx3+/Xa6+9pt27d6tfv3665ppr9MQTT2jIkCHBbcaNG6eqqqoOP3fPPffoueee69IxGhsb5fV6u5oSEBOBQEDp6emxTiNuUDvcNnXqVGv8H//xH63x3/3ud9Z4RUWFNV5fX9+9xBJQZ7UjrCvlqqoqlZaWavPmzVq3bp1OnjypCRMmqLm5ucN2d911l2pra4Nj4cKF3cseQEKgdgBdE9bnlL/8LGjp0qUaOHCgqqurNXbs2GD83HPPlc/n69I+W1pa1NLSErzd2NgYTkoA4gC1A+ias3pP+fOvB8vMzOwQf+mllzRgwAANGzZMZWVlOn78eMh9+P1+eb3e4MjJyTmblADEAWoHYBfWe8pf1N7erm9/+9tqaGjQ22+/HYz/67/+qwYPHqzs7Gzt2LFDDz30kPLz8/Xaa69Z92N7tssfF1zHe8rdR+1wD+8p95zOake3l9ksLS3Vzp07O/xRSdLdd98d/PeVV16pQYMGafz48dq/f78uueSS0/bj8Xjk8Xi6mwaAOEPtAM7AdENpaam58MILzf/8z/90uu2xY8eMJFNRUdGlfQcCASOJwXB6BAKB7vzpJD1qByPZR2e1I6wrZWOMZs6cqVWrVmnDhg3Ky8vr9Ge2b98uSRo0aFA4hwKQQKgdQNeE1ZRLS0u1fPlyrVmzRmlpaaqrq5Mkeb1e9evXT/v379fy5cv1jW98Q/3799eOHTs0e/ZsjR07tlvfYAQgMVA7gC7q0utC/59CXI6Xl5cbY4w5ePCgGTt2rMnMzDQej8dceuml5sEHHwzrpT5egmLEw+Dl6/CE+j1SOxjJNjp7THd79nW0sCoP4gGzr91D7UA8iOiKXgAAIHpoygAAOIKmDACAI2jKAAA4gqYMAIAjaMoAADjCuabs2Ce0ACsep+7h/wTxoLPHqXNNuampKdYpAJ3iceoe/k8QDzp7nDq3eEh7e7sOHTqktLQ0NTU1KScnRzU1NUmxUMPnXz3H+brLGKOmpiZlZ2crNdW557RJjdrB+bqsq7Wj21/dGC2pqam68MILJUkpKSmSpPT09Lj5xUcC5+s2Vo1yE7WD83VdV2oHT/UBAHAETRkAAEc43ZQ9Ho/mz58vj8cT61R6BOcLREayPbY438Th3EQvAACSldNXygAAJBOaMgAAjqApAwDgCJoyAACOoCkDAOAIp5vy4sWLddFFF6lv374qKCjQO++8E+uUImLjxo264YYblJ2drZSUFK1evbrD/cYYzZs3T4MGDVK/fv1UVFSkvXv3xibZCPD7/Ro1apTS0tI0cOBATZo0SXv27OmwzYkTJ1RaWqr+/fvr/PPP19SpU1VfXx+jjBHPErVuSMlVO5K1bjjblF955RXNmTNH8+fP17vvvqsRI0aouLhYhw8fjnVqZ625uVkjRozQ4sWLrfcvXLhQixYt0nPPPactW7bovPPOU3FxsU6cONHDmUZGVVWVSktLtXnzZq1bt04nT57UhAkT1NzcHNxm9uzZeuONN7Ry5UpVVVXp0KFDmjJlSgyzRjxK5LohJVftSNq6YRyVn59vSktLg7fb2tpMdna28fv9Mcwq8iSZVatWBW+3t7cbn89nnnzyyWCsoaHBeDwe8/LLL8cgw8g7fPiwkWSqqqqMMafOr3fv3mblypXBbXbt2mUkmU2bNsUqTcShZKkbxiRf7UiWuuHklXJra6uqq6tVVFQUjKWmpqqoqEibNm2KYWbRd+DAAdXV1XU4d6/Xq4KCgoQ590AgIEnKzMyUJFVXV+vkyZMdznno0KHKzc1NmHNG9CVz3ZASv3YkS91wsikfOXJEbW1tysrK6hDPyspSXV1djLLqGZ+fX6Kee3t7u2bNmqXRo0dr2LBhkk6dc58+fZSRkdFh20Q5Z/SMZK4bUmLXjmSqG859dSMSW2lpqXbu3Km333471qkAiBPJVDecvFIeMGCAevXqddosuvr6evl8vhhl1TM+P79EPPcZM2Zo7dq1euutt4LfeyudOufW1lY1NDR02D4Rzhk9J5nrhpS4tSPZ6oaTTblPnz4aOXKkKisrg7H29nZVVlaqsLAwhplFX15ennw+X4dzb2xs1JYtW+L23I0xmjFjhlatWqX169crLy+vw/0jR45U7969O5zznj17dPDgwbg9Z/S8ZK4bUuLVjqStG7GeaRbKihUrjMfjMUuXLjXvvfeeufvuu01GRoapq6uLdWpnrampyWzbts1s27bNSDJPPfWU2bZtm/nggw+MMcY8/vjjJiMjw6xZs8bs2LHD3HjjjSYvL898+umnMc68e6ZPn268Xq/ZsGGDqa2tDY7jx48Ht7n33ntNbm6uWb9+vdm6daspLCw0hYWFMcwa8SiR64YxyVU7krVuONuUjTHmmWeeMbm5uaZPnz4mPz/fbN68OdYpRcRbb71lJJ02pk2bZow59dGGhx9+2GRlZRmPx2PGjx9v9uzZE9ukz4LtXCWZ8vLy4Daffvqpue+++8xXvvIVc+6555rJkyeb2tra2CWNuJWodcOY5KodyVo3+D5lAAAc4eR7ygAAJCOaMgAAjqApAwDgCJoyAACOoCkDAOAImjIAAI6gKQMA4AiaMgAAjqApAwDgCJoyAACOoCkDAOCI/wcPrSW3v/D6cgAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.subplot(221)\n",
        "plt.imshow(X_train[310], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(222)\n",
        "plt.imshow(X_train[515], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(223)\n",
        "plt.imshow(X_train[1210], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(224)\n",
        "plt.imshow(X_train[2150], cmap=plt.get_cmap('gray'))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# In each model block, add the following lines before model training:\n",
        "mlflow.autolog()\n",
        "\n",
        "with mlflow.start_run(run_name=\"basic\") as run:\n",
        "    # let's try a basic neural network for digit classification\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Dense(20, activation='sigmoid', input_shape=(784,)))\n",
        "    model.add(layers.Dense(20, activation='sigmoid'))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "    model.summary()\n",
        "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "    show_history(history)\n",
        "    loss, acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "    print(\"Test accuracy: {:5.2f}%\".format(100*acc))\n",
        "    loss, acc = model.evaluate(x_train, y_train, verbose=2)\n",
        "    print(\"Train accuracy: {:5.2f}%\".format(100*acc))\n",
        "    # check if the prediction is working fine for a random test point\n",
        "    test_pt = 782\n",
        "    plt.imshow(X_test[test_pt], cmap=plt.get_cmap('gray'))\n",
        "    probs = model.predict(x_test[test_pt:test_pt+1], verbose=True)\n",
        "    print(\"Predicted Digit:\", np.argmax(probs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STUGA6DTX0Wr",
        "outputId": "3d4a7f32-1823-46ed-e3a1-dc27f25510ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 256)               200960    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 235146 (918.54 KB)\n",
            "Trainable params: 235146 (918.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# In each model block, add the following lines before model training:\n",
        "mlflow.autolog()\n",
        "\n",
        "with mlflow.start_run(run_name=\"bigger\") as run:\n",
        "    # Let's try with a slightly bigger model with more parameters.\n",
        "    model2 = keras.Sequential()\n",
        "    model2.add(layers.Dense(256, activation='sigmoid', input_shape=(784,)))\n",
        "    model2.add(layers.Dense(128, activation='sigmoid'))\n",
        "    model2.add(layers.Dense(10, activation='softmax'))\n",
        "    model2.summary()\n",
        "    model2.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    history = model2.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "    show_history(history)\n",
        "    loss, acc = model2.evaluate(x_test, y_test, verbose=2)\n",
        "    print(\"Test accuracy: {:5.2f}%\".format(100*acc))\n",
        "    loss, acc = model2.evaluate(x_train, y_train, verbose=2)\n",
        "    print(\"Train accuracy: {:5.2f}%\".format(100*acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XerbxmZFX0Ws",
        "outputId": "faba5967-7f6d-48fc-ddfb-0c96161deaba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_15 (Dense)            (None, 256)               200960    \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 235146 (918.54 KB)\n",
            "Trainable params: 235146 (918.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# In each model block, add the following lines before model training:\n",
        "mlflow.autolog()\n",
        "\n",
        "with mlflow.start_run(run_name=\"regularized\") as run:\n",
        "    # let's try adding kernel regularization to the mix.\n",
        "    model_r = keras.Sequential()\n",
        "    model_r.add(layers.Dense(256, activation='sigmoid', input_shape=(784,), kernel_regularizer=regularizers.L2(0.01)))\n",
        "    model_r.add(layers.Dense(128, activation='sigmoid', kernel_regularizer=regularizers.L2(0.01)))\n",
        "    model_r.add(layers.Dense(10, activation='softmax'))\n",
        "    model_r.summary()\n",
        "    model_r.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    history_r = model_r.fit(x_train, y_train, epochs=50, steps_per_epoch=50, validation_data=(x_test, y_test))\n",
        "    loss, acc = model_r.evaluate(x_test, y_test, verbose=2)\n",
        "    print(\"Test accuracy: {:5.2f}%\".format(100*acc))\n",
        "    loss, acc = model_r.evaluate(x_train, y_train, verbose=2)\n",
        "    print(\"Train accuracy: {:5.2f}%\".format(100*acc))\n",
        "    show_history(history_r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u94rHsDeX0Wt",
        "outputId": "725af822-704e-4bc1-fe7a-852725d8148a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_18 (Dense)            (None, 256)               200960    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 235146 (918.54 KB)\n",
            "Trainable params: 235146 (918.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# In each model block, add the following lines before model training:\n",
        "mlflow.autolog()\n",
        "\n",
        "with mlflow.start_run(run_name=\"dropout\") as run:\n",
        "    model_rd = keras.Sequential()\n",
        "    model_rd.add(layers.Dense(256, activation='sigmoid', input_shape=(784,)))\n",
        "    model_rd.add(Dropout(0.7))\n",
        "    model_rd.add(layers.Dense(128, activation='sigmoid'))\n",
        "    model_rd.add(Dropout(0.6))\n",
        "    model_rd.add(layers.Dense(10, activation='softmax'))\n",
        "    model_rd.summary()\n",
        "    model_rd.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    history_rd = model_rd.fit(x_train, y_train, epochs=10)\n",
        "    show_history(history_rd)\n",
        "    loss, acc = model_rd.evaluate(x_test, y_test, verbose=2)\n",
        "    print(\"Test accuracy: {:5.2f}%\".format(100*acc))\n",
        "    loss, acc = model_rd.evaluate(x_train, y_train, verbose=2)\n",
        "    print(\"Train accuracy: {:5.2f}%\".format(100*acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heSSzR0NX0Wu",
        "outputId": "a020cef9-4cb7-4c2d-e8d1-4ce3158c8b8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_21 (Dense)            (None, 256)               200960    \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 235146 (918.54 KB)\n",
            "Trainable params: 235146 (918.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# In each model block, add the following lines before model training:\n",
        "mlflow.autolog()\n",
        "\n",
        "with mlflow.start_run(run_name=\"early\") as run:\n",
        "    model_re = keras.Sequential()\n",
        "    model_re.add(layers.Dense(256, activation='sigmoid', input_shape=(784,)))\n",
        "    model_re.add(layers.Dense(128, activation='sigmoid'))\n",
        "    model_re.add(layers.Dense(10, activation='softmax'))\n",
        "    model_re.summary()\n",
        "    model_re.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    # model will get saved at the end of every epoch automatically.\n",
        "    checkpoint = ModelCheckpoint(r\"mnist-epoch-{epoch:02d}.hdf5\")\n",
        "    history_es = model_re.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test), callbacks=[checkpoint])\n",
        "    show_history(history_es)\n",
        "    es = keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0.01, patience=2)\n",
        "    model_re.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test), callbacks=[es])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OaQ05dFZX0Wu",
        "outputId": "c6d4d63d-6cb5-4b30-a2bc-623c30f466f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_24 (Dense)            (None, 20)                15700     \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 10)                210       \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 10)                110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,020\n",
            "Trainable params: 16,020\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# In each model block, add the following lines before model training:\n",
        "mlflow.autolog()\n",
        "\n",
        "with mlflow.start_run(run_name=\"learning\") as run:\n",
        "    # Using LEarning rates now.\n",
        "    model3 = keras.Sequential()\n",
        "    model3.add(layers.Dense(20, activation='sigmoid', input_shape=(784,)))\n",
        "    model3.add(layers.Dense(10, activation='sigmoid'))\n",
        "    model3.add(layers.Dense(10, activation='softmax'))\n",
        "    model3.summary()\n",
        "    opt_new = keras.optimizers.SGD(learning_rate=10)\n",
        "    model3.compile(optimizer=opt_new, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model3.fit(x_train, y_train, epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utdp9nTIX0Wu",
        "outputId": "1f178de5-c10b-443f-99b7-f7251756ada9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_27 (Dense)            (None, 20)                15700     \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 10)                210       \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 10)                110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,020\n",
            "Trainable params: 16,020\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.4651 - accuracy: 0.1124\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.4618 - accuracy: 0.1123\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.4586 - accuracy: 0.1123\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.4555 - accuracy: 0.1123\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.4524 - accuracy: 0.1123\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.4494 - accuracy: 0.1123\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.4465 - accuracy: 0.1123\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.4437 - accuracy: 0.1123\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.4409 - accuracy: 0.1123\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.4382 - accuracy: 0.1123\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.4356 - accuracy: 0.1123\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.4330 - accuracy: 0.1122\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.4304 - accuracy: 0.1122\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.4280 - accuracy: 0.1121\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.4255 - accuracy: 0.1121\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.4232 - accuracy: 0.1121\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.4208 - accuracy: 0.1120\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.4186 - accuracy: 0.1120\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.4164 - accuracy: 0.1119\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.4142 - accuracy: 0.1118\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe8ef768ac0>"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# In each model block, add the following lines before model training:\n",
        "mlflow.autolog()\n",
        "\n",
        "with mlflow.start_run(run_name=\"low\") as run:\n",
        "    # too low learning rate\n",
        "    model3 = keras.Sequential()\n",
        "    model3.add(layers.Dense(20, activation='sigmoid', input_shape=(784,)))\n",
        "    model3.add(layers.Dense(10, activation='sigmoid'))\n",
        "    model3.add(layers.Dense(10, activation='softmax'))\n",
        "    model3.summary()\n",
        "    opt_new = keras.optimizers.SGD(learning_rate=.00001)\n",
        "    model3.compile(optimizer=opt_new, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model3.fit(x_train, y_train, epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDRm_MSIX0Wv",
        "outputId": "04c0d651-32d4-4380-ffcd-a9803f41a704"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_30 (Dense)            (None, 20)                15700     \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 10)                210       \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 10)                110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,020\n",
            "Trainable params: 16,020\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.2533 - accuracy: 0.2392\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.0421 - accuracy: 0.4538\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.7108 - accuracy: 0.5248\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.4371 - accuracy: 0.5789\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.2426 - accuracy: 0.6340\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.0870 - accuracy: 0.6922\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.9525 - accuracy: 0.7380\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.8378 - accuracy: 0.7800\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7438 - accuracy: 0.8126\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6700 - accuracy: 0.8333\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6132 - accuracy: 0.8471\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5690 - accuracy: 0.8567\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5337 - accuracy: 0.8638\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5048 - accuracy: 0.8697\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4806 - accuracy: 0.8759\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4600 - accuracy: 0.8806\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4420 - accuracy: 0.8847\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4262 - accuracy: 0.8882\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4118 - accuracy: 0.8924\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3988 - accuracy: 0.8948\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe8ef55e2b0>"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# In each model block, add the following lines before model training:\n",
        "mlflow.autolog()\n",
        "\n",
        "with mlflow.start_run(run_name=\"optimal\") as run:\n",
        "    # optimal learning rate\n",
        "    model3 = keras.Sequential()\n",
        "    model3.add(layers.Dense(20, activation='sigmoid', input_shape=(784,)))\n",
        "    model3.add(layers.Dense(10, activation='sigmoid'))\n",
        "    model3.add(layers.Dense(10, activation='softmax'))\n",
        "    model3.summary()\n",
        "    opt_new = keras.optimizers.SGD(learning_rate=.01)\n",
        "    model3.compile(optimizer=opt_new, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model3.fit(x_train, y_train, epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yT-zGT4X0Wv",
        "outputId": "d1b5b671-cf5f-4660-f4f8-ef975710584d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_36 (Dense)            (None, 20)                15700     \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 10)                210       \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 10)                110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,020\n",
            "Trainable params: 16,020\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 2.1416 - accuracy: 0.3215\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.5759 - accuracy: 0.5187\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.1739 - accuracy: 0.6662\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.9175 - accuracy: 0.7466\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7481 - accuracy: 0.8101\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6318 - accuracy: 0.8464\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.5512 - accuracy: 0.8671\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4933 - accuracy: 0.8799\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.4498 - accuracy: 0.8889\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4166 - accuracy: 0.8957\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3901 - accuracy: 0.9013\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3687 - accuracy: 0.9047\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3507 - accuracy: 0.9087\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3355 - accuracy: 0.9121\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3223 - accuracy: 0.9156\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3107 - accuracy: 0.9180\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3002 - accuracy: 0.9201\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2906 - accuracy: 0.9229\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2818 - accuracy: 0.9247\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2734 - accuracy: 0.9268\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe8ec0b1e20>"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# In each model block, add the following lines before model training:\n",
        "mlflow.autolog()\n",
        "\n",
        "with mlflow.start_run(run_name=\"momentum\") as run:\n",
        "    # optimal learning rate with momentum\n",
        "    model3 = keras.Sequential()\n",
        "    model3.add(layers.Dense(20, activation='sigmoid', input_shape=(784,)))\n",
        "    model3.add(layers.Dense(10, activation='sigmoid'))\n",
        "    model3.add(layers.Dense(10, activation='softmax'))\n",
        "    model3.summary()\n",
        "    opt_new = keras.optimizers.SGD(learning_rate=.01, momentum=0.5)\n",
        "    model3.compile(optimizer=opt_new, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model3.fit(x_train, y_train, epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VLCo-_vX0Wv",
        "outputId": "e5eb6c7b-a9fe-42db-ea90-31458a2faccd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_60 (Dense)            (None, 20)                15700     \n",
            "                                                                 \n",
            " dense_61 (Dense)            (None, 10)                210       \n",
            "                                                                 \n",
            " dense_62 (Dense)            (None, 10)                110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,020\n",
            "Trainable params: 16,020\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 2.1100 - accuracy: 0.3083\n",
            "Epoch 2/10\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.7772 - accuracy: 0.5403\n",
            "Epoch 3/10\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.5238 - accuracy: 0.5899\n",
            "Epoch 4/10\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.3072 - accuracy: 0.6781\n",
            "Epoch 5/10\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.1206 - accuracy: 0.7504\n",
            "Epoch 6/10\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.9618 - accuracy: 0.7803\n",
            "Epoch 7/10\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.8310 - accuracy: 0.7980\n",
            "Epoch 8/10\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7264 - accuracy: 0.8153\n",
            "Epoch 9/10\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.6445 - accuracy: 0.8308\n",
            "Epoch 10/10\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.5787 - accuracy: 0.8457\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe8e0065e20>"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# In each model block, add the following lines before model training:\n",
        "mlflow.autolog()\n",
        "\n",
        "with mlflow.start_run(run_name=\"mini\") as run:\n",
        "    # Mini-batch SGD\n",
        "    # the default minibatch size is 32 unlike 1.\n",
        "    model4 = keras.Sequential()\n",
        "    model4.add(layers.Dense(20, activation='sigmoid', input_shape=(784,)))\n",
        "    model4.add(layers.Dense(10, activation='sigmoid'))\n",
        "    model4.add(layers.Dense(10, activation='softmax'))\n",
        "    model4.summary()\n",
        "    opt_new = keras.optimizers.SGD(learning_rate=.01, momentum=0.5)\n",
        "    model4.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model4.fit(x_train, y_train, batch_size=512, epochs=10)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
