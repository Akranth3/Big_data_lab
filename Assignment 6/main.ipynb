{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) train input samples\n",
      "(10000, 784) test input samples\n",
      "(60000, 10) train output samples\n",
      "(10000, 10) test output samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akranth/anaconda3/envs/big_data_lab/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-04-26 10:19:33.290517: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-26 10:19:33.293515: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">200,960</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m200,960\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,146</span> (918.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m235,146\u001b[0m (918.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,146</span> (918.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m235,146\u001b[0m (918.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 10:19:33.770007: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1874/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8054 - loss: 0.7009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 10:19:38.676188: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 31360000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8055 - loss: 0.7006 - val_accuracy: 0.9424 - val_loss: 0.1933\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9438 - loss: 0.1863 - val_accuracy: 0.9496 - val_loss: 0.1553\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9607 - loss: 0.1290 - val_accuracy: 0.9685 - val_loss: 0.1073\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9725 - loss: 0.0902 - val_accuracy: 0.9698 - val_loss: 0.0933\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9787 - loss: 0.0711 - val_accuracy: 0.9718 - val_loss: 0.0894\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9805 - loss: 0.0607 - val_accuracy: 0.9778 - val_loss: 0.0742\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9862 - loss: 0.0469 - val_accuracy: 0.9772 - val_loss: 0.0776\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9874 - loss: 0.0392 - val_accuracy: 0.9795 - val_loss: 0.0708\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9899 - loss: 0.0336 - val_accuracy: 0.9789 - val_loss: 0.0736\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9917 - loss: 0.0265 - val_accuracy: 0.9774 - val_loss: 0.0814\n",
      "313/313 - 0s - 1ms/step - accuracy: 0.9774 - loss: 0.0814\n",
      "Test accuracy: 97.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 10:20:19.987815: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 - 1s - 738us/step - accuracy: 0.9913 - loss: 0.0270\n",
      "Train accuracy: 99.13%\n"
     ]
    }
   ],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = keras.datasets.mnist.load_data()\n",
    "num_classes = 10\n",
    "x_train = X_train.reshape(60000, 784)\n",
    "x_test = X_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape, 'train input samples')\n",
    "print(x_test.shape, 'test input samples')\n",
    "\n",
    "y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(Y_test, num_classes)\n",
    "print(y_train.shape, 'train output samples')\n",
    "print(y_test.shape, 'test output samples')\n",
    "\n",
    "model2 = keras.Sequential()\n",
    "model2.add(layers.Dense(256, activation='sigmoid', input_shape=(784,)))\n",
    "model2.add(layers.Dense(128, activation='sigmoid'))\n",
    "model2.add(layers.Dense(10, activation='softmax'))\n",
    "model2.summary()\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model2.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
    "\n",
    "loss, acc = model2.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Test accuracy: {:5.2f}%\".format(100*acc))\n",
    "loss, acc = model2.evaluate(x_train, y_train, verbose=2)\n",
    "print(\"Train accuracy: {:5.2f}%\".format(100*acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pickle_file = \"models/model2.pkl\"\n",
    "\n",
    "# Save the model2 object to the pickle file\n",
    "with open(pickle_file, \"wb\") as f:\n",
    "    pickle.dump(model2, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, File, UploadFile\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "import io\n",
    "import PIL.Image\n",
    "import PIL.ImageOps\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_file, \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "app = FastAPI()\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_model(path: str) -> Sequential:\n",
    "    with open(path, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_digit(model: Sequential, data_point: list) -> str:\n",
    "    import numpy as np\n",
    "    \n",
    "    # Reshape the data_point to match the input shape of the model\n",
    "    data_point = np.array(data_point).reshape(1, 784)\n",
    "    \n",
    "    # Normalize the data_point\n",
    "    data_point = data_point.astype('float32') / 255\n",
    "    \n",
    "    # Predict the digit using the model\n",
    "    prediction = model.predict(data_point)\n",
    "    \n",
    "    # Get the predicted digit as a string\n",
    "    predicted_digit = str(np.argmax(prediction))\n",
    "    \n",
    "    return predicted_digit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, File, UploadFile\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "import io\n",
    "import PIL.Image\n",
    "import PIL.ImageOps\n",
    "import numpy as np\n",
    "\n",
    "app = FastAPI()\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "@app.post(\"/predict/\")\n",
    "async def predict(file: UploadFile = File(...)):\n",
    "    contents = await file.read()\n",
    "    pil_image = Image.open(io.BytesIO(contents)).convert(\"L\")\n",
    "    pil_image = PIL.ImageOps.invert(pil_image)\n",
    "    pil_image = pil_image.resize((28, 28), PIL.Image.ANTIALIAS)\n",
    "    image_array = np.array(pil_image).reshape(1, -1)\n",
    "    digit = predict_digit(model, image_array.tolist())\n",
    "\n",
    "    return {\"digit\": digit}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.post(\"/predict/\")\n",
    "async def predict(file: UploadFile = File(...)):\n",
    "    contents = await file.read()\n",
    "    pil_image = Image.open(io.BytesIO(contents)).convert(\"L\")\n",
    "    pil_image = PIL.ImageOps.invert(pil_image)\n",
    "    pil_image = pil_image.resize((28, 28), PIL.Image.ANTIALIAS)\n",
    "    image_array = np.array(pil_image).reshape(1, -1)\n",
    "    predictions = model.predict(image_array)\n",
    "\n",
    "    return {\"prediction\": predictions.argmax()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uvicorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     uvicorn\u001b[38;5;241m.\u001b[39mrun(app, host\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m127.0.0.1\u001b[39m\u001b[38;5;124m'\u001b[39m, port\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8000\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/big_data_lab/lib/python3.12/site-packages/uvicorn/main.py:575\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(app, host, port, uds, fd, loop, http, ws, ws_max_size, ws_max_queue, ws_ping_interval, ws_ping_timeout, ws_per_message_deflate, lifespan, interface, reload, reload_dirs, reload_includes, reload_excludes, reload_delay, workers, env_file, log_config, log_level, access_log, proxy_headers, server_header, date_header, forwarded_allow_ips, root_path, limit_concurrency, backlog, limit_max_requests, timeout_keep_alive, timeout_graceful_shutdown, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_version, ssl_cert_reqs, ssl_ca_certs, ssl_ciphers, headers, use_colors, app_dir, factory, h11_max_incomplete_event_size)\u001b[0m\n\u001b[1;32m    573\u001b[0m     Multiprocess(config, target\u001b[38;5;241m=\u001b[39mserver\u001b[38;5;241m.\u001b[39mrun, sockets\u001b[38;5;241m=\u001b[39m[sock])\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 575\u001b[0m     server\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39muds \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(config\u001b[38;5;241m.\u001b[39muds):\n\u001b[1;32m    577\u001b[0m     os\u001b[38;5;241m.\u001b[39mremove(config\u001b[38;5;241m.\u001b[39muds)  \u001b[38;5;66;03m# pragma: py-win32\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/big_data_lab/lib/python3.12/site-packages/uvicorn/server.py:65\u001b[0m, in \u001b[0;36mServer.run\u001b[0;34m(self, sockets)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, sockets: \u001b[38;5;28mlist\u001b[39m[socket\u001b[38;5;241m.\u001b[39msocket] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39msetup_event_loop()\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserve(sockets\u001b[38;5;241m=\u001b[39msockets))\n",
      "File \u001b[0;32m~/anaconda3/envs/big_data_lab/lib/python3.12/asyncio/runners.py:190\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug, loop_factory)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug\u001b[38;5;241m=\u001b[39mdebug, loop_factory\u001b[38;5;241m=\u001b[39mloop_factory) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(main)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    uvicorn.run(app, host='127.0.0.1', port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Sequential name=sequential, built=True>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   4   0   0   0   3   0   0   2   0   0\n",
      "    0   5   2   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   8  12   4   0   0   5   1   0   2   5   5   1   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   7   0   0   5   0   0   2   0\n",
      "    7   4   0   0   0   4   4   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0  11   0   0   0   0   4   6   0   1   2   0   0   0   2   1   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   1   9  10   1   0\n",
      "    2   2   0   1   7   7   5   4   3   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   2   0   3   1   0   0   0   0   0\n",
      "    0   4   0   0   0   0   0   0   0   0   0   0   0   0   0  18  14  28\n",
      "   81  96  81  88  91  83  81  81  61  25   1   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0  12  82 125 172 246 255 241 255 246 244 255 255\n",
      "  220 132  50  10   0   0   0   0   0   8   0   0  12   0   0  84 161 236\n",
      "  251 255 250 255 249 246 255 237 250 247 255 235 212  55   0   0  11   6\n",
      "    0   0   1   5   2   0  19 121 255 244 250 250 233 242 255 255 231 252\n",
      "  255 251 234 255 252  85  16   3   0   0  11   0   0   8   0   0 115 250\n",
      "  247 230 255 211 219 212 203 179   4  13   0   5  59 238 252  77   0   0\n",
      "    0   3   0   4   2   0   7  66 233 253 255 255 206   0   2   6   0   0\n",
      "    0   8   0   6  31 195 253 142  24  14   3   3   0   4   2   2   4  30\n",
      "  245 255 241 251 200   0   3   5   0   0  11   9   0   0   0  90 235 255\n",
      "   27   0   3   0  11   0   0   5   0  42 240 255 142  95  82   6   0   0\n",
      "    6   4   1   0   0   9   9  30 165 238  59   0   0   0   0   6   0   0\n",
      "    8 216 255 135  14   0   0   5   0   0   4   0   3   7   0   0   0   0\n",
      "  139 255 203  19   9   0   0   1   4   0   3 255 223 111   0  23   0   0\n",
      "    0  10   0   0   0  12   0   0   2  22 142 250 247   3   0   1   0   3\n",
      "    0   0   0 255 148  13   3   0   0   8   0   0   2   0   0   2   5   0\n",
      "   97 149 235 255 168  17   0   0   6   0   3   9   3 240 227  52   0   6\n",
      "    5   1   0   0  14   0   0   0 104 128 245 241 255 244  60   0   0  10\n",
      "    0   0   0   0   0 255 254 205  52  19   0   0   0  29 116 173 172 189\n",
      "  208 239 255 255 245 143   4   0  13   2   9   9   0   0  27 242 250 250\n",
      "  224 207 201 223 214 200 234 255 252 229 253 247 252 254 129  23   8   9\n",
      "   13   0   0   1   7   0   0  39 252 255 241 254 254 255 251 255 255 250\n",
      "  255 251 255 223 182   0   0   2   0   2   1   0  16   9   0   0  12  21\n",
      "  177 204 255 255 241 249 244 236 247 238 154 169 160  10  11   8   7   0\n",
      "    0   0   0   0   0   0   1   3   1   9   0  58 114 112 163 253 253 172\n",
      "  124 105   3  14   0   7   1   0   0   1   5   6   2   1  11   0   0   5\n",
      "    0   0   4   0   7   0  17  80  78  23   4   0   9   0   3   4   0   0\n",
      "    7   0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " array([[9.9997556e-01, 8.3440383e-09, 2.4128063e-05, 3.1972105e-09,\n",
       "         1.2544617e-10, 1.8584910e-07, 1.0202413e-07, 4.8068213e-08,\n",
       "         2.1138013e-11, 8.2970466e-09]], dtype=float32))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "image_path = \"../../archive/testSample/img_2.jpg\"\n",
    "image = Image.open(image_path)\n",
    "print(np.array(image).reshape(1, 784))\n",
    "np.argmax(model.predict(np.array(image).reshape(1, 784))), model.predict(np.array(image).reshape(1, 784))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"models/model2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [   255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      251,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      252,\n",
    "      255,\n",
    "      255,\n",
    "      253,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      250,\n",
    "      253,\n",
    "      255,\n",
    "      255,\n",
    "      250,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      247,\n",
    "      243,\n",
    "      251,\n",
    "      255,\n",
    "      255,\n",
    "      250,\n",
    "      254,\n",
    "      255,\n",
    "      253,\n",
    "      250,\n",
    "      250,\n",
    "      254,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      248,\n",
    "      255,\n",
    "      255,\n",
    "      250,\n",
    "      255,\n",
    "      255,\n",
    "      253,\n",
    "      255,\n",
    "      248,\n",
    "      251,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      251,\n",
    "      251,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      244,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      251,\n",
    "      249,\n",
    "      255,\n",
    "      254,\n",
    "      253,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      253,\n",
    "      254,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      254,\n",
    "      246,\n",
    "      245,\n",
    "      254,\n",
    "      255,\n",
    "      253,\n",
    "      253,\n",
    "      255,\n",
    "      254,\n",
    "      248,\n",
    "      248,\n",
    "      250,\n",
    "      251,\n",
    "      252,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      253,\n",
    "      255,\n",
    "      252,\n",
    "      254,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      251,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      237,\n",
    "      241,\n",
    "      227,\n",
    "      174,\n",
    "      159,\n",
    "      174,\n",
    "      167,\n",
    "      164,\n",
    "      172,\n",
    "      174,\n",
    "      174,\n",
    "      194,\n",
    "      230,\n",
    "      254,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      243,\n",
    "      173,\n",
    "      130,\n",
    "      83,\n",
    "      9,\n",
    "      0,\n",
    "      14,\n",
    "      0,\n",
    "      9,\n",
    "      11,\n",
    "      0,\n",
    "      0,\n",
    "      35,\n",
    "      123,\n",
    "      205,\n",
    "      245,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      247,\n",
    "      255,\n",
    "      255,\n",
    "      243,\n",
    "      255,\n",
    "      255,\n",
    "      171,\n",
    "      94,\n",
    "      19,\n",
    "      4,\n",
    "      0,\n",
    "      5,\n",
    "      0,\n",
    "      6,\n",
    "      9,\n",
    "      0,\n",
    "      18,\n",
    "      5,\n",
    "      8,\n",
    "      0,\n",
    "      20,\n",
    "      43,\n",
    "      200,\n",
    "      255,\n",
    "      255,\n",
    "      244,\n",
    "      249,\n",
    "      255,\n",
    "      255,\n",
    "      254,\n",
    "      250,\n",
    "      253,\n",
    "      255,\n",
    "      236,\n",
    "      134,\n",
    "      0,\n",
    "      11,\n",
    "      5,\n",
    "      5,\n",
    "      22,\n",
    "      13,\n",
    "      0,\n",
    "      0,\n",
    "      24,\n",
    "      3,\n",
    "      0,\n",
    "      4,\n",
    "      21,\n",
    "      0,\n",
    "      3,\n",
    "      170,\n",
    "      239,\n",
    "      252,\n",
    "      255,\n",
    "      255,\n",
    "      244,\n",
    "      255,\n",
    "      255,\n",
    "      247,\n",
    "      255,\n",
    "      255,\n",
    "      140,\n",
    "      5,\n",
    "      8,\n",
    "      25,\n",
    "      0,\n",
    "      44,\n",
    "      36,\n",
    "      43,\n",
    "      52,\n",
    "      76,\n",
    "      251,\n",
    "      242,\n",
    "      255,\n",
    "      250,\n",
    "      196,\n",
    "      17,\n",
    "      3,\n",
    "      178,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      252,\n",
    "      255,\n",
    "      251,\n",
    "      253,\n",
    "      255,\n",
    "      248,\n",
    "      189,\n",
    "      22,\n",
    "      2,\n",
    "      0,\n",
    "      0,\n",
    "      49,\n",
    "      255,\n",
    "      253,\n",
    "      249,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      247,\n",
    "      255,\n",
    "      249,\n",
    "      224,\n",
    "      60,\n",
    "      2,\n",
    "      113,\n",
    "      231,\n",
    "      241,\n",
    "      252,\n",
    "      252,\n",
    "      255,\n",
    "      251,\n",
    "      253,\n",
    "      253,\n",
    "      251,\n",
    "      225,\n",
    "      10,\n",
    "      0,\n",
    "      14,\n",
    "      4,\n",
    "      55,\n",
    "      255,\n",
    "      252,\n",
    "      250,\n",
    "      255,\n",
    "      255,\n",
    "      244,\n",
    "      246,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      165,\n",
    "      20,\n",
    "      0,\n",
    "      228,\n",
    "      255,\n",
    "      252,\n",
    "      255,\n",
    "      244,\n",
    "      255,\n",
    "      255,\n",
    "      250,\n",
    "      255,\n",
    "      213,\n",
    "      15,\n",
    "      0,\n",
    "      113,\n",
    "      160,\n",
    "      173,\n",
    "      249,\n",
    "      255,\n",
    "      255,\n",
    "      249,\n",
    "      251,\n",
    "      254,\n",
    "      255,\n",
    "      255,\n",
    "      246,\n",
    "      246,\n",
    "      225,\n",
    "      90,\n",
    "      17,\n",
    "      196,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      249,\n",
    "      255,\n",
    "      255,\n",
    "      247,\n",
    "      39,\n",
    "      0,\n",
    "      120,\n",
    "      241,\n",
    "      255,\n",
    "      255,\n",
    "      250,\n",
    "      255,\n",
    "      255,\n",
    "      251,\n",
    "      255,\n",
    "      252,\n",
    "      248,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      116,\n",
    "      0,\n",
    "      52,\n",
    "      236,\n",
    "      246,\n",
    "      255,\n",
    "      255,\n",
    "      254,\n",
    "      251,\n",
    "      255,\n",
    "      252,\n",
    "      0,\n",
    "      32,\n",
    "      144,\n",
    "      255,\n",
    "      232,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      245,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      243,\n",
    "      255,\n",
    "      255,\n",
    "      253,\n",
    "      233,\n",
    "      113,\n",
    "      5,\n",
    "      8,\n",
    "      252,\n",
    "      255,\n",
    "      254,\n",
    "      255,\n",
    "      252,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      0,\n",
    "      107,\n",
    "      242,\n",
    "      252,\n",
    "      255,\n",
    "      255,\n",
    "      247,\n",
    "      255,\n",
    "      255,\n",
    "      253,\n",
    "      255,\n",
    "      255,\n",
    "      253,\n",
    "      250,\n",
    "      255,\n",
    "      158,\n",
    "      106,\n",
    "      20,\n",
    "      0,\n",
    "      87,\n",
    "      238,\n",
    "      255,\n",
    "      255,\n",
    "      249,\n",
    "      255,\n",
    "      252,\n",
    "      246,\n",
    "      252,\n",
    "      15,\n",
    "      28,\n",
    "      203,\n",
    "      255,\n",
    "      249,\n",
    "      250,\n",
    "      254,\n",
    "      255,\n",
    "      255,\n",
    "      241,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      151,\n",
    "      127,\n",
    "      10,\n",
    "      14,\n",
    "      0,\n",
    "      11,\n",
    "      195,\n",
    "      255,\n",
    "      255,\n",
    "      245,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      0,\n",
    "      1,\n",
    "      50,\n",
    "      203,\n",
    "      236,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      226,\n",
    "      139,\n",
    "      82,\n",
    "      83,\n",
    "      66,\n",
    "      47,\n",
    "      16,\n",
    "      0,\n",
    "      0,\n",
    "      10,\n",
    "      112,\n",
    "      251,\n",
    "      255,\n",
    "      242,\n",
    "      253,\n",
    "      246,\n",
    "      246,\n",
    "      255,\n",
    "      255,\n",
    "      228,\n",
    "      13,\n",
    "      5,\n",
    "      5,\n",
    "      31,\n",
    "      48,\n",
    "      54,\n",
    "      32,\n",
    "      41,\n",
    "      55,\n",
    "      21,\n",
    "      0,\n",
    "      3,\n",
    "      26,\n",
    "      2,\n",
    "      8,\n",
    "      3,\n",
    "      1,\n",
    "      126,\n",
    "      232,\n",
    "      247,\n",
    "      246,\n",
    "      242,\n",
    "      255,\n",
    "      255,\n",
    "      254,\n",
    "      248,\n",
    "      255,\n",
    "      255,\n",
    "      216,\n",
    "      3,\n",
    "      0,\n",
    "      14,\n",
    "      1,\n",
    "      1,\n",
    "      0,\n",
    "      4,\n",
    "      0,\n",
    "      0,\n",
    "      5,\n",
    "      0,\n",
    "      4,\n",
    "      0,\n",
    "      32,\n",
    "      73,\n",
    "      255,\n",
    "      255,\n",
    "      253,\n",
    "      255,\n",
    "      253,\n",
    "      254,\n",
    "      255,\n",
    "      239,\n",
    "      246,\n",
    "      255,\n",
    "      255,\n",
    "      243,\n",
    "      234,\n",
    "      78,\n",
    "      51,\n",
    "      0,\n",
    "      0,\n",
    "      14,\n",
    "      6,\n",
    "      11,\n",
    "      19,\n",
    "      8,\n",
    "      17,\n",
    "      101,\n",
    "      86,\n",
    "      95,\n",
    "      245,\n",
    "      244,\n",
    "      247,\n",
    "      248,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      254,\n",
    "      252,\n",
    "      254,\n",
    "      246,\n",
    "      255,\n",
    "      197,\n",
    "      141,\n",
    "      143,\n",
    "      92,\n",
    "      2,\n",
    "      2,\n",
    "      83,\n",
    "      131,\n",
    "      150,\n",
    "      252,\n",
    "      241,\n",
    "      255,\n",
    "      248,\n",
    "      254,\n",
    "      255,\n",
    "      255,\n",
    "      254,\n",
    "      250,\n",
    "      249,\n",
    "      253,\n",
    "      254,\n",
    "      244,\n",
    "      255,\n",
    "      255,\n",
    "      250,\n",
    "      255,\n",
    "      255,\n",
    "      251,\n",
    "      255,\n",
    "      248,\n",
    "      255,\n",
    "      238,\n",
    "      175,\n",
    "      177,\n",
    "      232,\n",
    "      251,\n",
    "      255,\n",
    "      246,\n",
    "      255,\n",
    "      252,\n",
    "      251,\n",
    "      255,\n",
    "      255,\n",
    "      248,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      250,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255,\n",
    "      255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.array(l).reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageOps\n\u001b[0;32m----> 3\u001b[0m inverted_l \u001b[38;5;241m=\u001b[39m ImageOps\u001b[38;5;241m.\u001b[39minvert(l)\n",
      "File \u001b[0;32m~/anaconda3/envs/big_data_lab/lib/python3.12/site-packages/PIL/ImageOps.py:630\u001b[0m, in \u001b[0;36minvert\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;124;03mInvert (negate) the image.\u001b[39;00m\n\u001b[1;32m    625\u001b[0m \n\u001b[1;32m    626\u001b[0m \u001b[38;5;124;03m:param image: The image to invert.\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;124;03m:return: An image.\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    629\u001b[0m lut \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image\u001b[38;5;241m.\u001b[39mpoint(lut) \u001b[38;5;28;01mif\u001b[39;00m image\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m _lut(image, lut)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'mode'"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(l, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big_data_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
